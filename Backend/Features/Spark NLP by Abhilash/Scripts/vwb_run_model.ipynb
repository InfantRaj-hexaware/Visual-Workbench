{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f3e2264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove_100d download started this may take some time.\n",
      "Approximate size to download 145.3 MB\n",
      "[OK!]\n",
      "+---------+------+\n",
      "|chunk    |entity|\n",
      "+---------+------+\n",
      "|revenue  |Msr   |\n",
      "|region   |Cat   |\n",
      "|verticals|Cat   |\n",
      "|deparment|Cat   |\n",
      "+---------+------+\n",
      "\n",
      "\n",
      "\n",
      "parameter[0] {'Categorical Dimension': [], 'Goal Measure': [], 'Measure': ['revenue'], 'Timeline Dimension': []}\n",
      "\n",
      " pdf->\n",
      "       chunk entity\n",
      "0    revenue    Msr\n",
      "1     region    Cat\n",
      "2  verticals    Cat\n",
      "3  deparment    Cat\n",
      "\n",
      "\n",
      "[{\"chunk\":\"revenue\",\"entity\":\"Msr\"},{\"chunk\":\"region\",\"entity\":\"Cat\"},{\"chunk\":\"verticals\",\"entity\":\"Cat\"},{\"chunk\":\"deparment\",\"entity\":\"Cat\"}]\n",
      "\n",
      "\n",
      "Spark NLP NER Entities are created\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from pyspark.ml import Pipeline\n",
    "import pyspark.sql.functions as F\n",
    "import pandas as pd\n",
    "\n",
    "import sparknlp\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator  import *\n",
    "\n",
    "#spark = sparknlp.start(spark32=True) #If we are using spark = 3.2.0 and above\n",
    "spark = sparknlp.start()\n",
    "\n",
    "#print(\"Spark NLP version: \", sparknlp.version())\n",
    "#print(\"Apache Spark version: \", spark.version)\n",
    "\n",
    "spark\n",
    "\n",
    "#userStory = str(input())\n",
    "# userStory = 'I would like to visualize profit achieved last year and also the loss incurred, What is the targeted revenue and profit for the next year.'\n",
    "userStory = 'Show me the revenue across different region, different verticals and across different deparment.'\n",
    "\n",
    "sample_data = spark.createDataFrame([[userStory]]).toDF(\"text\")\n",
    "\n",
    "def get_ann_model():\n",
    "    document = DocumentAssembler()\\\n",
    "        .setInputCol(\"text\")\\\n",
    "        .setOutputCol(\"document\")\n",
    "\n",
    "    sentence = SentenceDetector()\\\n",
    "        .setInputCols(['document'])\\\n",
    "        .setOutputCol('sentence')\n",
    "\n",
    "    token = Tokenizer()\\\n",
    "        .setInputCols(['sentence'])\\\n",
    "        .setOutputCol('token')\n",
    "\n",
    "    glove_embeddings = WordEmbeddingsModel.pretrained('glove_100d')\\\n",
    "        .setInputCols([\"document\", \"token\"])\\\n",
    "        .setOutputCol(\"embeddings\")\n",
    "  \n",
    "# load trained model\n",
    "    loaded_ner_model = NerDLModel.load(\"Vwb_NER_glove_e5_b32\")\\\n",
    "        .setInputCols([\"sentence\", \"token\", \"embeddings\"])\\\n",
    "        .setOutputCol(\"ner\")\n",
    "\n",
    "    converter = NerConverter()\\\n",
    "        .setInputCols([\"document\", \"token\", \"ner\"])\\\n",
    "        .setOutputCol(\"ner_span\")\n",
    "\n",
    "    ner_prediction_pipeline = Pipeline(stages = [\n",
    "        document,\n",
    "        sentence,\n",
    "        token,\n",
    "        glove_embeddings,\n",
    "        loaded_ner_model,\n",
    "        converter\n",
    "    ])\n",
    "\n",
    "    empty_data = spark.createDataFrame([['']]).toDF(\"text\")\n",
    "\n",
    "    prediction_model = ner_prediction_pipeline.fit(empty_data)\\\n",
    "\n",
    "    preds = prediction_model.transform(sample_data)\n",
    "     \n",
    "    preds.select(F.explode(F.arrays_zip(preds.ner_span.result,preds.ner_span.metadata)).alias(\"entities\")) \\\n",
    "      .select(F.expr(\"entities['0']\").alias(\"chunk\"),\n",
    "              F.expr(\"entities['1'].entity\").alias(\"entity\")).show(truncate=False)\n",
    "    \n",
    "    pdf = preds.select(F.explode(F.arrays_zip(preds.ner_span.result,preds.ner_span.metadata)).alias(\"entities\")) \\\n",
    "      .select(F.expr(\"entities['0']\").alias(\"chunk\"),\n",
    "              F.expr(\"entities['1'].entity\").alias(\"entity\")).toPandas()\n",
    "    \n",
    "    #pdf = pd.DataFrame([{\"chunk\":\"profit\",\"entity\":\"Goal\"},{\"chunk\":\"last year\",\"entity\":\"Tmln\"},{\"chunk\":\"targeted revenue\",\"entity\":\"Goal\"},{\"chunk\":\"profit\",\"entity\":\"Goal\"},{\"chunk\":\"next year\",\"entity\":\"Tmln\"}])\n",
    "    parameter = [{'Categorical Dimension' : [],\n",
    "             'Goal Measure' : [],\n",
    "             'Measure' : [],\n",
    "             'Timeline Dimension' : []}]\n",
    "    for i in range(len(pdf)):\n",
    "        if pdf.loc[i, \"entity\"] == 'cat':\n",
    "            parameter[0]['Categorical Dimension'].append(pdf.loc[i, \"chunk\"])\n",
    "        if pdf.loc[i, \"entity\"] == 'Goal':\n",
    "            parameter[0]['Goal Measure'].append(pdf.loc[i, \"chunk\"])\n",
    "        if pdf.loc[i, \"entity\"] == 'Msr':\n",
    "            parameter[0]['Measure'].append(pdf.loc[i, \"chunk\"])\n",
    "        if pdf.loc[i, \"entity\"] == 'Tmln':\n",
    "            parameter[0]['Timeline Dimension'].append(pdf.loc[i, \"chunk\"])\n",
    "    print('\\n')\n",
    "    print('parameter[0]',parameter[0])\n",
    "    \n",
    "    print('\\n pdf->')\n",
    "    print(pdf)\n",
    "    \n",
    "    jason = pdf.to_json(orient = 'records')\n",
    "    \n",
    "    print('\\n')\n",
    "    print(jason)\n",
    "    \n",
    "    print('\\n')\n",
    "    print (\"Spark NLP NER Entities are created\")\n",
    "    \n",
    "    return parameter[0]\n",
    "\n",
    "\n",
    "model = get_ann_model()\n",
    "\n",
    "#get_ann_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4bd2d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Categorical Dimension': [], 'Goal Measure': ['revenue'], 'Measure': [], 'Timeline Dimension': []}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a63c62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
